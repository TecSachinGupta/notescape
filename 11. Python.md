# Python 


## Decorators

### Theory
Decorators implement the **Decorator Pattern**, a structural design pattern that allows behavior to be added to objects dynamically without altering their structure. In Python, decorators are essentially **higher-order functions** that take a function as input and return a modified version of that function.

The decorator mechanism leverages Python's **first-class functions** concept - functions are objects that can be passed around, stored in variables, and returned from other functions. When you use `@decorator_name`, Python internally calls `decorator_name(original_function)` and replaces the original function with the returned value.

**Key Theoretical Concepts:**
- **Closure**: Decorators often use closures to maintain access to variables from their enclosing scope
- **Function Introspection**: Decorators can access and modify function metadata
- **Separation of Concerns**: Cross-cutting concerns (logging, timing, authentication) are separated from business logic

Decorators are functions that modify or extend the behavior of other functions without permanently modifying them. They use the `@` symbol and are placed above function definitions.

### Basic Decorator Pattern
```python
def my_decorator(func):
    def wrapper(*args, **kwargs):
        # Code before function execution
        result = func(*args, **kwargs)
        # Code after function execution
        return result
    return wrapper

@my_decorator
def my_function():
    pass
```

### Common Built-in Decorators
- `@property` - Creates getter methods
- `@staticmethod` - Methods that don't access instance or class data
- `@classmethod` - Methods that receive the class as first argument

## Generators

### Theory
Generators are based on the **Iterator Protocol** and implement **lazy evaluation**. They represent a fundamental shift from **eager evaluation** (computing all values at once) to **lazy evaluation** (computing values on-demand). This is crucial for memory efficiency and enables processing of infinite sequences.

**Theoretical Foundations:**
- **Coroutines**: Generators are a form of coroutine - functions that can be paused and resumed
- **State Machine**: Each generator maintains its own execution state between yields
- **Memory Efficiency**: O(1) space complexity regardless of sequence length
- **Infinite Sequences**: Can represent mathematically infinite sequences
- **Pipeline Processing**: Enable functional programming patterns for data processing

The `yield` keyword transforms a regular function into a generator function. When called, it returns a generator object rather than executing the function body immediately. The function's execution is suspended at each `yield` statement and resumed when `next()` is called.

Generators are functions that return an iterator object and yield values one at a time, making them memory-efficient for large datasets.

### Generator Functions
```python
def my_generator():
    yield 1
    yield 2
    yield 3

# Generator expressions
gen = (x**2 for x in range(10))
```

### Generator Methods
- `next()` - Get next value
- `send()` - Send value to generator
- `throw()` - Throw exception into generator
- `close()` - Close generator

## Regular Expressions

### Theory
Regular expressions are based on **formal language theory** and **automata theory**. They represent a formal language for describing patterns in strings, originally developed by mathematician Stephen Kleene.

**Theoretical Foundations:**
- **Finite State Automata**: Regex engines use finite state machines to match patterns
- **Regular Languages**: Regex can only match regular languages (Type 3 in Chomsky hierarchy)
- **Deterministic vs Non-deterministic**: Modern engines use optimized algorithms like NFA with backtracking
- **Greedy vs Lazy Matching**: Quantifiers can be greedy (match as much as possible) or lazy (match as little as possible)
- **Compilation**: Patterns are compiled into bytecode for efficient execution

**Pattern Matching Process:**
1. **Lexical Analysis**: Pattern is tokenized into components
2. **Parsing**: Tokens are parsed into an abstract syntax tree
3. **Compilation**: AST is converted to executable bytecode
4. **Execution**: Bytecode is executed against the input string

Regular expressions (regex) are patterns used to match character combinations in strings.

### Common Patterns
- `.` - Any character except newline
- `*` - Zero or more occurrences
- `+` - One or more occurrences
- `?` - Zero or one occurrence
- `^` - Start of string
- `$` - End of string
- `\d` - Digit
- `\w` - Word character
- `\s` - Whitespace

### Key Functions
```python
import re
re.match()    # Match at beginning
re.search()   # Search anywhere
re.findall()  # Find all matches
re.sub()      # Replace matches
re.compile()  # Compile pattern
```

## List/Tuple/Dictionary Operations

### Theory
These data structures represent different **Abstract Data Types (ADTs)** with distinct theoretical properties:

**Lists (Dynamic Arrays):**
- **Amortized Analysis**: Append operations are O(1) amortized due to dynamic resizing
- **Memory Layout**: Elements stored contiguously in memory for cache efficiency
- **Growth Strategy**: Typically grows by ~37.5% when capacity is exceeded
- **Mutability**: Supports in-place modifications

**Tuples (Immutable Sequences):**
- **Immutability Theory**: Once created, cannot be modified (provides thread safety)
- **Hash Consistency**: Immutable objects can be hashed and used as dictionary keys
- **Memory Optimization**: More memory-efficient than lists due to fixed size
- **Structural Sharing**: Can share memory with other tuples in some implementations

**Dictionaries (Hash Tables):**
- **Hash Function Theory**: Uses hash functions to map keys to array indices
- **Collision Resolution**: Python uses open addressing with random probing
- **Load Factor**: Maintains load factor to balance time/space complexity
- **Dynamic Resizing**: Automatically resizes when load factor exceeds threshold
- **Average Case**: O(1) average time complexity for lookups, insertions, deletions

### Lists
- Mutable, ordered collections
- Methods: `append()`, `extend()`, `insert()`, `remove()`, `pop()`, `sort()`, `reverse()`
- Slicing: `list[start:end:step]`

### Tuples
- Immutable, ordered collections
- Methods: `count()`, `index()`
- Tuple unpacking: `a, b, c = (1, 2, 3)`

### Dictionaries
- Mutable, unordered key-value pairs
- Methods: `get()`, `keys()`, `values()`, `items()`, `pop()`, `update()`
- Dictionary comprehensions: `{k: v for k, v in items}`

## Iterators

### Theory
Iterators implement the **Iterator Design Pattern** and are fundamental to Python's **iteration protocol**. They provide a uniform interface for traversing different data structures.

**Theoretical Concepts:**
- **Iterator Protocol**: Defines `__iter__()` and `__next__()` methods as a contract
- **Lazy Evaluation**: Elements are generated on-demand, not pre-computed
- **Stateful**: Maintains position in the sequence between calls
- **One-way Traversal**: Can only move forward through the sequence
- **Exhaustion**: Once exhausted, iterator raises StopIteration for all subsequent calls

**Mathematical Foundation:**
- **Sequence Theory**: Iterators represent mathematical sequences
- **Finite vs Infinite**: Can represent both finite and infinite sequences
- **Composition**: Multiple iterators can be composed together (iterator chains)

**Memory Model:**
- **Constant Space**: O(1) space complexity regardless of sequence length
- **Streaming**: Enables processing of data streams larger than available memory

Objects that implement the iterator protocol with `__iter__()` and `__next__()` methods.

### Iterator Protocol
```python
class MyIterator:
    def __init__(self, data):
        self.data = data
        self.index = 0
    
    def __iter__(self):
        return self
    
    def __next__(self):
        if self.index >= len(self.data):
            raise StopIteration
        value = self.data[self.index]
        self.index += 1
        return value
```

### Built-in Iterator Functions
- `iter()` - Create iterator
- `next()` - Get next item
- `enumerate()` - Add counter to iterable
- `zip()` - Combine iterables
- `map()` - Apply function to iterable
- `filter()` - Filter items

## Class/Static Methods

### Theory
These method types represent different **binding strategies** and **scope relationships** in object-oriented programming:

**Instance Methods:**
- **Implicit Binding**: `self` parameter is automatically bound to the instance
- **Dynamic Dispatch**: Method resolution follows Method Resolution Order (MRO)
- **State Access**: Full access to instance state and class state

**Static Methods:**
- **No Binding**: No automatic parameter binding
- **Namespace Organization**: Logically related to class but independent of instance/class state
- **Utility Functions**: Often used for utility functions related to the class
- **Early Binding**: Resolved at compile time, not runtime

**Class Methods:**
- **Class Binding**: `cls` parameter automatically bound to the class
- **Factory Pattern**: Commonly used to implement factory methods
- **Inheritance Aware**: `cls` refers to the actual class that called the method
- **Alternative Constructors**: Enable multiple ways to create instances

**Descriptor Protocol:**
All method types use Python's **descriptor protocol** (`__get__`, `__set__`, `__delete__`) to implement their binding behavior.

### Instance Methods
Regular methods that receive `self` as first parameter and can access instance attributes.

### Static Methods
```python
class MyClass:
    @staticmethod
    def static_method():
        # No access to self or cls
        pass
```

### Class Methods
```python
class MyClass:
    @classmethod
    def class_method(cls):
        # Receives class as first parameter
        pass
```

## List Comprehensions

### Theory
List comprehensions are based on **set-builder notation** from mathematics and represent a **declarative programming** paradigm within Python's primarily imperative structure.

**Theoretical Foundations:**
- **Set Theory**: Syntax mirrors mathematical set-builder notation: {x | x ∈ S, P(x)}
- **Functional Programming**: Implements map/filter operations in a single expression
- **Lazy vs Eager**: List comprehensions are eager (computed immediately)
- **Syntactic Sugar**: Internally converted to equivalent for-loops by Python
- **Cartesian Products**: Nested comprehensions can represent mathematical Cartesian products

**Compilation Process:**
1. **Parsing**: Expression parsed into AST (Abstract Syntax Tree)
2. **Transformation**: AST transformed into equivalent loop structure
3. **Optimization**: Bytecode optimizer may apply loop optimizations
4. **Execution**: Executed as optimized bytecode

**Performance Theory:**
- **Constant Factor**: ~2x faster than equivalent for-loops due to optimized C implementation
- **Memory Allocation**: Pre-allocates result list when size is known
- **Loop Fusion**: Multiple operations fused into single loop iteration

Concise way to create lists using a single line of code.

### Basic Syntax
```python
[expression for item in iterable if condition]

# Examples
squares = [x**2 for x in range(10)]
evens = [x for x in range(20) if x % 2 == 0]
```

### Nested Comprehensions
```python
matrix = [[j for j in range(3)] for i in range(3)]
```

### Dictionary/Set Comprehensions
```python
# Dictionary comprehension
{k: v for k, v in items if condition}

# Set comprehension
{x for x in iterable if condition}
```

## OOP Concepts

### Theory
Object-Oriented Programming is based on several fundamental theoretical concepts from computer science:

**Class Theory:**
- **Abstract Data Types**: Classes define both data structure and operations
- **Encapsulation**: Data and methods are bundled together, hiding internal implementation
- **Type System**: Classes define new types in the language's type system
- **Instantiation**: Process of creating objects from class templates

**Inheritance Theory:**
- **IS-A Relationship**: Models taxonomic relationships between entities
- **Method Resolution Order (MRO)**: C3 linearization algorithm determines method lookup order
- **Liskov Substitution Principle**: Subtypes must be substitutable for their base types
- **Diamond Problem**: Multiple inheritance can create ambiguous method resolution

**Polymorphism Theory:**
- **Ad-hoc Polymorphism**: Method overloading (different signatures)
- **Parametric Polymorphism**: Generic programming with type parameters
- **Subtype Polymorphism**: Different classes implementing same interface
- **Dynamic Dispatch**: Method selection happens at runtime based on object type

**Encapsulation Levels:**
- **Public**: Accessible from anywhere
- **Protected**: Accessible within class hierarchy (convention: single underscore)
- **Private**: Accessible only within class (convention: double underscore)

**Memory Model:**
- **Object Layout**: Objects store instance variables in dictionaries or slots
- **Reference Semantics**: Variables store references to objects, not objects themselves
- **Garbage Collection**: Automatic memory management through reference counting and cycle detection

### Classes and Objects
```python
class MyClass:
    class_variable = "shared"
    
    def __init__(self, value):
        self.instance_variable = value
    
    def method(self):
        return self.instance_variable
```

### Inheritance
```python
class Parent:
    def method(self):
        pass

class Child(Parent):
    def method(self):
        super().method()  # Call parent method
        # Additional functionality
```

### Encapsulation
- Private attributes: `_attribute` (convention)
- Name mangling: `__attribute`
- Properties: `@property`, `@attribute.setter`

### Polymorphism
Same interface, different implementations through method overriding.

### Special Methods (Dunder Methods)
- `__init__()` - Constructor
- `__str__()` - String representation
- `__len__()` - Length
- `__eq__()` - Equality comparison
- `__add__()` - Addition operator

## Mutability

### Theory
Mutability is a fundamental concept in **programming language theory** that affects **semantics**, **performance**, and **safety**.

**Theoretical Foundations:**
- **Value vs Reference Semantics**: Immutable objects use value semantics, mutable objects use reference semantics
- **Aliasing**: Multiple variables can reference the same mutable object, creating aliases
- **Side Effects**: Mutations create side effects that can lead to non-deterministic behavior
- **Referential Transparency**: Immutable objects preserve referential transparency

**Memory Management:**
- **Copy vs Share**: Immutable objects can be safely shared between contexts
- **Interning**: Python interns small integers and strings for memory efficiency
- **Garbage Collection**: Immutable objects simplify garbage collection

**Concurrency Theory:**
- **Thread Safety**: Immutable objects are inherently thread-safe
- **Race Conditions**: Mutable objects can create race conditions in concurrent programs
- **Atomic Operations**: Mutations may require atomic operations for consistency

**Functional Programming:**
- **Persistent Data Structures**: Immutable data structures that share structure between versions
- **Pure Functions**: Functions that don't mutate their inputs are easier to reason about
- **Caching**: Immutable objects can be safely cached (memoization)

**Performance Implications:**
- **Copy Overhead**: Immutable objects may require copying for "modifications"
- **Memory Locality**: Mutable objects may have better cache performance
- **Optimization**: Compilers can optimize immutable objects more aggressively

### Mutable Objects
Objects that can be changed after creation:
- Lists, dictionaries, sets
- Custom objects (by default)

### Immutable Objects
Objects that cannot be changed after creation:
- Strings, tuples, frozensets
- Numbers (int, float, complex)
- Boolean values

### Implications
- Mutable objects can be modified in-place
- Immutable objects create new objects when "modified"
- Be careful with mutable default arguments

## Lambda Functions

### Theory
Lambda functions are rooted in **lambda calculus**, a formal system developed by Alonzo Church that forms the theoretical foundation of functional programming.

**Mathematical Foundation:**
- **Lambda Calculus**: Formal system for expressing computation based on function abstraction and application
- **Anonymous Functions**: Functions without names, defined inline
- **Higher-Order Functions**: Functions that take other functions as arguments or return functions
- **Currying**: Technique of transforming multi-argument functions into single-argument functions

**Theoretical Properties:**
- **Expression-based**: Lambda functions are expressions, not statements
- **Closure**: Can capture variables from enclosing scope
- **First-class Citizens**: Can be passed as arguments, returned from functions, stored in data structures
- **Lexical Scoping**: Variables resolved based on where function is defined, not where it's called

**Computational Theory:**
- **Church-Turing Thesis**: Lambda calculus is equivalent in computational power to Turing machines
- **Reduction**: Lambda expressions can be reduced (simplified) through α-conversion, β-reduction, and η-conversion
- **Combinators**: Lambda expressions that contain no free variables

**Limitations in Python:**
- **Single Expression**: Unlike pure lambda calculus, Python lambdas limited to single expressions
- **No Statements**: Cannot contain assignments, loops, or other statements
- **Debugging**: Harder to debug due to anonymous nature

Anonymous functions defined with the `lambda` keyword.

### Syntax
```python
lambda arguments: expression

# Examples
add = lambda x, y: x + y
square = lambda x: x**2
```

### Common Use Cases
- With `map()`, `filter()`, `sorted()`
- Short, simple functions
- Callback functions

### Functions vs Lambda
- Functions are more readable for complex logic
- Lambda limited to single expressions
- Functions can have docstrings and multiple statements

## Egg/Wheel Packaging

### Theory
Python packaging systems are based on **software distribution theory** and **dependency management** concepts.

**Distribution Theory:**
- **Source vs Binary**: Source distributions contain source code, binary distributions contain pre-compiled code
- **Platform Specificity**: Binary distributions are platform-specific, source distributions are platform-independent
- **Dependency Resolution**: Complex problem of finding compatible versions of all dependencies
- **Semantic Versioning**: Version numbering scheme that conveys meaning about compatibility

**Wheel Format Theory:**
- **ZIP-based**: Wheels are ZIP archives with specific structure and metadata
- **Installation Speed**: Binary format eliminates compilation step during installation
- **Platform Tags**: Encoded platform information (e.g., cp39-cp39-win_amd64)
- **Metadata**: Standardized metadata format for dependencies, entry points, etc.

**Package Management:**
- **Namespace Packages**: Packages split across multiple distributions
- **Entry Points**: Plugin system for discovering and loading code
- **Virtual Environments**: Isolated Python environments for dependency management
- **Lock Files**: Exact dependency versions for reproducible builds

**Security Considerations:**
- **Code Signing**: Cryptographic signatures to verify package integrity
- **Sandboxing**: Isolated execution environments for untrusted code
- **Vulnerability Scanning**: Automated detection of security issues in dependencies

### Egg Format (Legacy)
- Older Python package format
- `.egg` files
- Being phased out in favor of wheels

### Wheel Format (Modern)
- Standard binary package format
- `.whl` files
- Faster installation than source distributions

### Package Structure
```
mypackage/
├── setup.py
├── setup.cfg
├── pyproject.toml
├── README.md
├── LICENSE
└── mypackage/
    ├── __init__.py
    └── module.py
```

### Building Packages
```bash
pip install build
python -m build
```

## Config Files

### Common Formats
- **JSON**: `json.load()`, `json.dump()`
- **YAML**: `yaml.safe_load()`, `yaml.safe_dump()`
- **INI**: `configparser.ConfigParser()`
- **TOML**: `tomllib.load()` (Python 3.11+)

### Environment Variables
```python
import os
value = os.getenv('ENV_VAR', 'default_value')
```

### Configuration Best Practices
- Separate config from code
- Use environment-specific configs
- Validate configuration values
- Document configuration options

## Performance Questions

### Time Complexity
- **O(1)**: Dictionary lookup, list append
- **O(n)**: List search, iteration
- **O(n log n)**: Sorting
- **O(n²)**: Nested loops

### Memory Optimization
- Use generators for large datasets
- Prefer list comprehensions over loops
- Use `__slots__` for classes with many instances
- Consider using `array.array` for numeric data

### Profiling Tools
- `cProfile` - Function-level profiling
- `line_profiler` - Line-by-line profiling
- `memory_profiler` - Memory usage profiling
- `timeit` - Timing small code snippets

### Performance Tips
- Use built-in functions and libraries
- Avoid premature optimization
- Cache expensive computations
- Use appropriate data structures
- Consider using NumPy for numerical operations