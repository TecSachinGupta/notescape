# Data Modeling & Architecture

## Entity-Relationship (ER) Models

Entity-Relationship models are conceptual frameworks used to represent the structure of a database. They define how data entities relate to each other within a system.

### Core Components

**Entities** represent real-world objects or concepts (e.g., Customer, Product, Order). Each entity has attributes that describe its properties, such as a Customer having a name, email, and phone number.

**Relationships** define how entities interact with each other. These connections can be one-to-one, one-to-many, or many-to-many. For example, a Customer can place multiple Orders (one-to-many), while an Order can contain multiple Products and a Product can be in multiple Orders (many-to-many).

**Attributes** are the properties of entities and relationships. They can be simple (atomic values), composite (made up of multiple components), or derived (calculated from other attributes).

### ER Diagram Symbols

Rectangles represent entities, diamonds represent relationships, and ovals represent attributes. Lines connect these elements to show their associations, with cardinality indicators showing the nature of relationships.

## Database Schemas

Database schemas define the logical structure and organization of data within a database system. Different schema types serve various purposes in data modeling and warehousing.

### Star Schema

The star schema is the simplest dimensional model, consisting of a central fact table surrounded by dimension tables. Each dimension table is directly connected to the fact table, creating a star-like structure.

This design denormalizes dimension tables for optimal query performance, making it easy to understand and navigate. The star schema provides fast aggregation and is ideal for simple queries, though it may result in data redundancy in dimension tables.

### Snowflake Schema

The snowflake schema is a normalized version of the star schema where dimension tables are further broken down into subdimensions. This creates a tree-like structure resembling a snowflake.

While this normalization reduces data redundancy and storage requirements, it introduces more complex joins and can impact query performance. The snowflake schema is beneficial when dimension tables are large and contain hierarchical data.

### Galaxy Schema (Fact Constellation)

The galaxy schema contains multiple fact tables that share common dimension tables. This design supports multiple business processes and enables cross-process analysis.

It's more complex than star or snowflake schemas but provides flexibility for organizations with multiple data marts. The galaxy schema allows for integrated reporting across different business functions.

### Third Normal Form (3NF)

3NF is a normalized schema design that eliminates data redundancy by ensuring each non-key attribute depends only on the primary key. This approach minimizes storage space and maintains data integrity.

While 3NF reduces redundancy, it requires more complex queries with multiple joins, making it less suitable for analytical workloads but ideal for transactional systems.

## Fact and Dimension Tables

Fact and dimension tables form the foundation of dimensional modeling in data warehousing, particularly in star and snowflake schemas.

### Fact Tables

Fact tables store quantitative data for analysis and are often denormalized. They contain foreign keys to dimension tables and measures (numeric values) that can be aggregated. Examples include sales transactions, website clicks, or financial records.

Fact tables typically have a composite primary key made up of foreign keys from related dimension tables. They focus on storing business events and their associated metrics, such as sales amount, quantity sold, or profit margin.

### Dimension Tables

Dimension tables provide context for the facts by storing descriptive attributes. They are usually denormalized and contain the details that answer "who," "what," "where," "when," and "why" questions about the facts.

Common dimension tables include time (date, month, year), geography (country, state, city), product (category, brand, model), and customer (demographics, segments). These tables enable slicing and dicing of fact data for analysis.

## CAP Theorem

The CAP theorem states that in any distributed data system, you can guarantee at most two of the following three properties simultaneously:

### Consistency

All nodes see the same data at the same time. Every read receives the most recent write or an error. Strong consistency ensures that all replicas have identical data, but this can impact availability and partition tolerance.

### Availability

The system remains operational and responsive. Every request receives a response, even if some nodes are down. High availability systems continue to function despite failures, but may serve stale data.

### Partition Tolerance

The system continues to operate despite network failures that prevent nodes from communicating. This is essential for distributed systems, as network partitions are inevitable in real-world deployments.

### Trade-offs

Different database systems make different CAP trade-offs. Traditional SQL databases often choose consistency over availability, while NoSQL systems like eventual consistency models prioritize availability and partition tolerance.

## MongoDB Architecture

MongoDB is a document-oriented NoSQL database that stores data in flexible, JSON-like documents within collections.

### Document Structure

Documents are stored in BSON (Binary JSON) format, which supports rich data types including arrays, embedded documents, and various primitive types. This flexibility allows for schema evolution without requiring migrations.

### Collections and Databases

Collections are groups of documents, similar to tables in relational databases, but without enforced schema. Multiple collections exist within databases, and MongoDB instances can host multiple databases.

### Replication and Sharding

MongoDB uses replica sets for high availability, where multiple servers maintain copies of the same data. Sharding distributes data across multiple servers based on a shard key, enabling horizontal scaling.

### Indexing

MongoDB supports various index types including single field, compound, multikey, geospatial, and text indexes. Proper indexing is crucial for query performance, especially as collections grow large.

## HBase Reads

HBase is a distributed, column-oriented NoSQL database built on top of Hadoop's HDFS, designed for random, real-time read/write access to large datasets.

### Row Key Design

HBase stores data in tables with row keys that determine data distribution and access patterns. Well-designed row keys prevent hotspotting and enable efficient range scans. Common patterns include reverse timestamps, hashing, and composite keys.

### Column Families

Data is organized into column families, which group related columns together. Column families are defined at table creation time and should be used to separate data with different access patterns or retention requirements.

### Read Path

HBase reads first check the MemStore (in-memory cache), then HFiles (on-disk storage), and finally the Write-Ahead Log if necessary. The RegionServer manages this process, potentially reading from multiple HFiles and merging results.

### Performance Optimization

Efficient HBase reads depend on proper row key design, appropriate column family structure, and effective use of filters. Bloom filters can reduce disk I/O by eliminating unnecessary file reads during get operations.

## OLAP vs OLTP Systems

OLAP (Online Analytical Processing) and OLTP (Online Transaction Processing) systems serve different purposes in data management and have distinct characteristics.

### OLTP (Online Transaction Processing)

OLTP systems are designed for managing day-to-day business operations and transactions. They handle high volumes of short, fast transactions with emphasis on data integrity and consistency.

**Characteristics of OLTP:**
- Optimized for INSERT, UPDATE, and DELETE operations
- Normalized database schemas (typically 3NF) to minimize redundancy
- High concurrency with many simultaneous users
- ACID compliance for transaction integrity
- Real-time processing with low latency requirements
- Detailed, current data at the operational level

**Examples** include e-commerce order processing, banking transactions, inventory management, and customer relationship management systems.

### OLAP (Online Analytical Processing)

OLAP systems are designed for complex analytical queries and business intelligence. They process large volumes of historical data to support decision-making through reporting and analysis.

**Characteristics of OLAP:**
- Optimized for SELECT and complex analytical queries
- Denormalized schemas (star/snowflake) for faster query performance
- Lower concurrency with fewer simultaneous users
- Focus on read performance over write consistency
- Batch processing with acceptable latency for complex queries
- Aggregated, historical data for trend analysis

**Examples** include data warehouses, business intelligence dashboards, financial reporting systems, and market analysis platforms.

### Key Differences

**Data Structure:** OLTP uses normalized schemas to prevent anomalies, while OLAP uses denormalized schemas for query performance.

**Query Complexity:** OLTP handles simple, frequent queries, while OLAP processes complex analytical queries with aggregations and joins.

**Data Volume:** OLTP manages current operational data, while OLAP handles large volumes of historical data.

**Performance Focus:** OLTP prioritizes transaction speed and consistency, while OLAP emphasizes query performance and analytical capabilities.

**Update Frequency:** OLTP requires real-time updates, while OLAP typically updates through scheduled batch processes.

## NoSQL vs SQL Differences

The choice between NoSQL and SQL databases depends on specific use cases, data structures, and scalability requirements.

### Schema Flexibility

SQL databases enforce rigid schemas with predefined tables, columns, and data types. Changes require schema migrations that can be complex and time-consuming. NoSQL databases offer flexible or schema-less designs that accommodate evolving data structures without migrations.

### Scalability Approaches

SQL databases traditionally scale vertically by adding more power to existing servers. They can be challenging to scale horizontally due to ACID compliance requirements. NoSQL databases are designed for horizontal scaling, distributing data across multiple servers more easily.

### Query Capabilities

SQL provides a standardized, powerful query language with complex joins, aggregations, and transactions. NoSQL databases often use simpler query interfaces specific to their data models, though some support SQL-like query languages.

### ACID Properties

SQL databases strictly enforce ACID (Atomicity, Consistency, Isolation, Durability) properties, ensuring data integrity through transactions. NoSQL databases often relax these constraints in favor of performance and scalability, implementing eventual consistency models.

### Use Case Alignment

SQL databases excel in applications requiring complex relationships, transactions, and analytical queries, such as financial systems and traditional business applications. NoSQL databases are ideal for big data, real-time applications, content management, and scenarios requiring rapid scaling.

### Data Relationships

SQL databases handle complex relationships through foreign keys and joins, making them suitable for normalized data structures. NoSQL databases often denormalize data and embed related information within documents or use different modeling approaches for relationships.